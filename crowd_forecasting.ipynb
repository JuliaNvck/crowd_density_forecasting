{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07d338-b87c-4fd8-9ab7-23162dc3a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd6c1d7-3241-4200-b854-72fde9617142",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa252b1-2a1b-456b-9d27-7abb6a6cb78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312c8e1-458b-409a-8158-b8ff479bd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28973e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pyarrow.parquet as pq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97817522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "#  Load Multiple Months of NYC TLC Data\n",
    "data_dir = \"data/taxi/\"\n",
    "months = [f\"2017-{str(m).zfill(2)}\" for m in range(1, 13)]\n",
    "all_dfs_train = []\n",
    "columns = [\n",
    "    'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "    'PULocationID', 'DOLocationID',\n",
    "    'passenger_count', 'fare_amount', 'congestion_surcharge'\n",
    "]\n",
    "\n",
    "for month in months:\n",
    "    file_path = os.path.join(data_dir, f\"yellow_tripdata_{month}.parquet\")\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_parquet(file_path, columns=columns)\n",
    "        df['pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "        df['dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "        df['pickup_hour'] = df['pickup_datetime'].dt.hour\n",
    "        df['pickup_day'] = df['pickup_datetime'].dt.dayofweek\n",
    "        df['pickup_zone'] = df['PULocationID']\n",
    "        df['dropoff_zone'] = df['DOLocationID']\n",
    "        df['day_type'] = df['pickup_datetime'].dt.day_name()\n",
    "        all_dfs_train.append(df)\n",
    "\n",
    "# Load January 2018 Yellow Taxi Data (Validation)\n",
    "val_month = \"2018-01\"\n",
    "val_df = pd.read_parquet(os.path.join(data_dir, f\"yellow_tripdata_{val_month}.parquet\"), columns=columns)\n",
    "val_df['pickup_datetime'] = pd.to_datetime(val_df['tpep_pickup_datetime'])\n",
    "val_df['dropoff_datetime'] = pd.to_datetime(val_df['tpep_dropoff_datetime'])\n",
    "val_df['pickup_hour'] = val_df['pickup_datetime'].dt.hour\n",
    "val_df['pickup_day'] = val_df['pickup_datetime'].dt.dayofweek\n",
    "val_df['pickup_zone'] = val_df['PULocationID']\n",
    "val_df['dropoff_zone'] = val_df['DOLocationID']\n",
    "val_df['day_type'] = val_df['pickup_datetime'].dt.day_name()\n",
    "\n",
    "# Combine\n",
    "trips_df = pd.concat(all_dfs_train, ignore_index=True)\n",
    "print(\"Training shape:\", trips_df.shape)\n",
    "\n",
    "# Find 50 most active drop-off zones\n",
    "top_zones = trips_df['DOLocationID'].value_counts().head(50).index.tolist()\n",
    "print(\"Top 50 most active drop-off zones:\", top_zones)\n",
    "\n",
    "# Keep only records where DOLocationID is in top zones\n",
    "trips_df = trips_df[trips_df['DOLocationID'].isin(top_zones)]\n",
    "\n",
    "# Filter val_df to same top zones\n",
    "val_df = val_df[val_df['DOLocationID'].isin(top_zones)]\n",
    "\n",
    "# One-hot encode day_type\n",
    "day_type_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "day_type_encoded = day_type_encoder.fit_transform(trips_df[['day_type']])\n",
    "day_type_encoded_val = day_type_encoder.transform(val_df[['day_type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96926fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Demand and more features by hour and zone\n",
    "grouped = trips_df.groupby(['dropoff_zone', pd.Grouper(key='dropoff_datetime', freq='1h')])\n",
    "agg = grouped.agg(\n",
    "    dropoff_count=('dropoff_zone', 'size'),\n",
    "    avg_fare_amount=('fare_amount', 'mean'),\n",
    "    avg_passenger_count=('passenger_count', 'mean'),\n",
    "    avg_congestion_surcharge=('congestion_surcharge', 'mean')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35109298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot for multivariate time series\n",
    "agg_pivoted = agg.pivot(index='dropoff_datetime', columns='dropoff_zone')\n",
    "agg_pivoted = agg_pivoted.fillna(0).infer_objects(copy=False)\n",
    "# Flatten multi-index columns\n",
    "agg_pivoted.columns = ['{}_{}'.format(metric, zone) for metric, zone in agg_pivoted.columns]\n",
    "# Append one-hot encoded day_type to agg_pivoted\n",
    "agg_pivoted_enriched = np.hstack([agg_pivoted.values, day_type_encoded[:agg_pivoted.shape[0]]])\n",
    "\n",
    "\n",
    "# Validation\n",
    "grouped_val = val_df.groupby(['dropoff_zone', pd.Grouper(key='dropoff_datetime', freq='1h')])\n",
    "agg_val = grouped_val.agg(\n",
    "    dropoff_count=('dropoff_zone', 'size'),\n",
    "    avg_fare_amount=('fare_amount', 'mean'),\n",
    "    avg_passenger_count=('passenger_count', 'mean'),\n",
    "    avg_congestion_surcharge=('congestion_surcharge', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "agg_pivoted_val = agg_val.pivot(index='dropoff_datetime', columns='dropoff_zone')\n",
    "agg_pivoted_val = agg_pivoted_val.fillna(0).infer_objects(copy=False)\n",
    "agg_pivoted_val = agg_pivoted_val.reindex(columns=agg_pivoted.columns, fill_value=0)\n",
    "# Append one-hot encoded day_type to validation\n",
    "agg_pivoted_val_enriched = np.hstack([agg_pivoted_val.values, day_type_encoded_val[:agg_pivoted_val.shape[0]]])\n",
    "\n",
    "# Standardize Features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(agg_pivoted_enriched)\n",
    "X_train_full = torch.tensor(scaled_data[:-1], dtype=torch.float)\n",
    "y_train_full = torch.tensor(scaled_data[1:], dtype=torch.float)\n",
    "\n",
    "scaled_val = scaler.transform(agg_pivoted_val_enriched)\n",
    "X_val = torch.tensor(scaled_val[:-1], dtype=torch.float)\n",
    "y_val = torch.tensor(scaled_val[1:], dtype=torch.float)\n",
    "\n",
    "X_train, y_train = X_train_full, y_train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711efeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract zone ids and edge index from co-visitation \n",
    "zone_ids = sorted(set(trips_df['dropoff_zone'].unique()))\n",
    "zone_to_idx = {z: i for i, z in enumerate(zone_ids)}\n",
    "\n",
    "# Build co-visitation edges/graph\n",
    "zone_transitions = trips_df.groupby(['pickup_zone', 'dropoff_zone']).size().reset_index(name='weight')\n",
    "zone_transitions = zone_transitions[zone_transitions['pickup_zone'].isin(zone_ids) & zone_transitions['dropoff_zone'].isin(zone_ids)]\n",
    "edge_index = torch.tensor(zone_transitions[['pickup_zone', 'dropoff_zone']].replace(zone_to_idx).values.T, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8796837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top co-visitation pairs (pickup - dropoff) by trip frequency\n",
    "print(zone_transitions.sort_values(by='weight', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNRNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, gnn_dim=32):\n",
    "        super(GNNRNNModel, self).__init__()\n",
    "        self.gcn = GCNConv(input_dim, gnn_dim)\n",
    "        self.rnn = nn.GRU(gnn_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        gnn_out = self.gcn(x, edge_index)\n",
    "        rnn_input = gnn_out.unsqueeze(0)  # (1, time, features)\n",
    "        rnn_out, _ = self.rnn(rnn_input)\n",
    "        output = self.fc(rnn_out.squeeze(0))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449498bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "model = GNNRNNModel(input_dim=X_train.shape[1])\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(X_train, edge_index)\n",
    "    loss = loss_fn(out, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # Evaluate on validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_out = model(X_val, edge_index)\n",
    "        val_loss = loss_fn(val_out, y_val)\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e09d0-6f1e-4118-ae9f-df5fcbc47510",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"last train MSE: \", losses[199])\n",
    "print(\"last val MSE: \", val_losses[199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ff5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Loss\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affe5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Step Forecasting (for 3 steps in future)\n",
    "model.eval()\n",
    "horizon = 3\n",
    "input_seq = X_train.clone()\n",
    "predictions = []\n",
    "for step in range(horizon):\n",
    "    output = model(input_seq, edge_index)\n",
    "    predictions.append(output[-1].unsqueeze(0))\n",
    "    input_seq = torch.cat([input_seq[1:], output[-1].unsqueeze(0)])\n",
    "\n",
    "multi_step_preds = torch.cat(predictions)\n",
    "multi_step_preds_np = multi_step_preds.detach().numpy()\n",
    "multi_step_preds_inv = scaler.inverse_transform(multi_step_preds_np)\n",
    "multi_step_preds_inv = np.clip(multi_step_preds_inv, a_min=0, a_max=None)\n",
    "\n",
    "print(\"Multi-step forecast shape:\", multi_step_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5dc2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Forecasted Zone Crowd Density Over Time (time steps)\n",
    "multi_step_real = multi_step_preds_inv\n",
    "feature_names = agg_pivoted.columns\n",
    "zone_features = [name for name in feature_names if name.startswith(\"dropoff_count_\")]\n",
    "zone_indices = [feature_names.get_loc(name) for name in zone_features]\n",
    "\n",
    "for step in range(horizon):\n",
    "    values = multi_step_real[step, zone_indices]\n",
    "    zone_ids_extracted = [int(name.split('_')[-1]) for name in zone_features]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=zone_ids_extracted, y=values)\n",
    "    plt.title(f\"Forecasted Drop-off Count by Zone - Step {step + 1}\")\n",
    "    plt.xlabel(\"Zone ID\")\n",
    "    plt.ylabel(\"Predicted Drop-off Count\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ddc49-e7af-42f1-b054-b6f7055bd3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def simulate_daytype_zone(model, X_seed, edge_index, scaler, feature_names, zone_id, day_type_encoder, target_daytype, horizon=24):\n",
    "    \"\"\"\n",
    "    Simulates predictions for a specific zone assuming a fixed day of the week (e.g., Monday vs Saturday) by modifying the day-of-week encoding.\n",
    "    Input: Trained model, last training window, zone ID, target_daytype (e.g., \"Saturday\")\n",
    "\n",
    "    Purpose: Run forecast like predict_generic_day_zone, but inject a fixed weekday/weekend identity\n",
    "\n",
    "    Modifies: Day-of-week one-hot encoding in input\n",
    "    \"\"\"\n",
    "    zone_key = f\"dropoff_count_{zone_id}\"\n",
    "    try:\n",
    "        zone_index = feature_names.index(zone_key)\n",
    "    except ValueError:\n",
    "        print(f\"Zone {zone_id} not found.\")\n",
    "        return\n",
    "\n",
    "    # Get one-hot vector for target day (e.g., \"Monday\")\n",
    "    day_vec = day_type_encoder.transform(pd.DataFrame({'day_type': [target_daytype]}))[0]\n",
    "\n",
    "    # Calculate where the day-type features begin\n",
    "    feature_start = X_seed.shape[1] - len(day_vec)\n",
    "\n",
    "    # Clone seed input and inject target day-type into each time step\n",
    "    input_seq = X_seed.clone()\n",
    "    input_seq[:, feature_start:] = torch.tensor(day_vec, dtype=torch.float)\n",
    "\n",
    "    # Step forward\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    for _ in range(horizon):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, edge_index)\n",
    "        predictions.append(output[-1].unsqueeze(0))\n",
    "\n",
    "        # Replace day_type vector in the predicted next step\n",
    "        next_input = output[-1].clone()\n",
    "        next_input[feature_start:] = torch.tensor(day_vec, dtype=torch.float)\n",
    "        input_seq = torch.cat([input_seq[1:], next_input.unsqueeze(0)])\n",
    "\n",
    "    preds = torch.cat(predictions).detach().numpy()\n",
    "    preds_inv = scaler.inverse_transform(preds)\n",
    "    zone_preds = np.clip(preds_inv[:, zone_index], 0, None)\n",
    "\n",
    "    # Plot\n",
    "    hours = list(range(horizon))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(hours, zone_preds)\n",
    "    plt.title(f\"Predicted Dropoffs for Zone {zone_id} on {target_daytype}\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Dropoff Count\")\n",
    "    plt.xticks(hours)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return list(zip(hours, zone_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca37fb9-b4b8-47cb-b2c1-b141d75715ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_daytype_zone(\n",
    "    model=model,\n",
    "    X_seed=X_train.clone(),\n",
    "    edge_index=edge_index,\n",
    "    scaler=scaler,\n",
    "    feature_names=agg_pivoted.columns.tolist(),\n",
    "    zone_id=107,\n",
    "    day_type_encoder=day_type_encoder,\n",
    "    target_daytype=\"Monday\"  # Weekday\n",
    ")\n",
    "\n",
    "simulate_daytype_zone(\n",
    "    model=model,\n",
    "    X_seed=X_train.clone(),\n",
    "    edge_index=edge_index,\n",
    "    scaler=scaler,\n",
    "    feature_names=agg_pivoted.columns.tolist(),\n",
    "    zone_id=107,\n",
    "    day_type_encoder=day_type_encoder,\n",
    "    target_daytype=\"Saturday\"  # Weekend\n",
    ")\n",
    "\n",
    "simulate_daytype_zone(\n",
    "    model=model,\n",
    "    X_seed=X_train.clone(),\n",
    "    edge_index=edge_index,\n",
    "    scaler=scaler,\n",
    "    feature_names=agg_pivoted.columns.tolist(),\n",
    "    zone_id=148,\n",
    "    day_type_encoder=day_type_encoder,\n",
    "    target_daytype=\"Monday\"  # Weekday\n",
    ")\n",
    "\n",
    "simulate_daytype_zone(\n",
    "    model=model,\n",
    "    X_seed=X_train.clone(),\n",
    "    edge_index=edge_index,\n",
    "    scaler=scaler,\n",
    "    feature_names=agg_pivoted.columns.tolist(),\n",
    "    zone_id=148,\n",
    "    day_type_encoder=day_type_encoder,\n",
    "    target_daytype=\"Saturday\"  # Weekend\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d9b01-a56e-4111-9baa-caccb52f4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def simulate_daytype_multi_zones(model, X_seed, edge_index, scaler, feature_names, zone_ids, day_type_encoder, target_daytype, horizon=24):\n",
    "    \"\"\"\n",
    "    Predicts 24-hour dropoff counts for multiple zones on a given day-type (e.g., Monday).\n",
    "    Plots all zones on one graph for easy comparison\n",
    "\n",
    "    Useful for comparing weekday vs weekend behavior across zones\n",
    "    \"\"\"\n",
    "    # Get one-hot day-type vector\n",
    "    day_vec = day_type_encoder.transform(pd.DataFrame({'day_type': [target_daytype]}))[0]\n",
    "    feature_start = X_seed.shape[1] - len(day_vec)\n",
    "\n",
    "    # Inject day-type into seed input\n",
    "    input_seq = X_seed.clone()\n",
    "    input_seq[:, feature_start:] = torch.tensor(day_vec, dtype=torch.float)\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(horizon):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, edge_index)\n",
    "        predictions.append(output[-1].unsqueeze(0))\n",
    "\n",
    "        # Inject fixed day-type for next step\n",
    "        next_input = output[-1].clone()\n",
    "        next_input[feature_start:] = torch.tensor(day_vec, dtype=torch.float)\n",
    "        input_seq = torch.cat([input_seq[1:], next_input.unsqueeze(0)])\n",
    "\n",
    "    preds = torch.cat(predictions).detach().numpy()\n",
    "    preds_inv = scaler.inverse_transform(preds)\n",
    "\n",
    "    # Plot all requested zones\n",
    "    hours = list(range(horizon))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for zone_id in zone_ids:\n",
    "        zone_key = f\"dropoff_count_{zone_id}\"\n",
    "        if zone_key not in feature_names:\n",
    "            print(f\"Zone {zone_id} not found, skipping.\")\n",
    "            continue\n",
    "        zone_index = feature_names.index(zone_key)\n",
    "        zone_preds = np.clip(preds_inv[:, zone_index], 0, None)\n",
    "        plt.plot(hours, zone_preds, label=f\"Zone {zone_id}\", marker='o')\n",
    "\n",
    "    plt.title(f\"Predicted Dropoff Count on {target_daytype}\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Dropoff Count\")\n",
    "    plt.xticks(hours)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf512c-f54d-460f-9222-052e3d26dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_daytype_multi_zones(\n",
    "    model=model,\n",
    "    X_seed=X_train.clone(),\n",
    "    edge_index=edge_index,\n",
    "    scaler=scaler,\n",
    "    feature_names=agg_pivoted.columns.tolist(),\n",
    "    zone_ids=[107, 148],\n",
    "    day_type_encoder=day_type_encoder,\n",
    "    target_daytype=\"Saturday\",  # or \"Monday\"\n",
    "    horizon=24\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cadea75-0317-4e27-a0fc-6c80ee450216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408748db-b54b-431c-addb-76640237e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_generic_day_zone(model, X_seed, edge_index, scaler, feature_names, zone_id, horizon=24):\n",
    "    \"\"\"\n",
    "    Predict dropoff counts for a specific zone over 24 future hours using the model.\n",
    "    Simulates a generic day by forecasting from the end of training data.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    zone_key = f\"dropoff_count_{zone_id}\"\n",
    "    try:\n",
    "        zone_index = feature_names.index(zone_key)\n",
    "    except ValueError:\n",
    "        print(f\"Zone {zone_id} not found in features.\")\n",
    "        return\n",
    "\n",
    "    model.eval()\n",
    "    input_seq = X_seed.clone()\n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(horizon):\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq, edge_index)\n",
    "        predictions.append(output[-1].unsqueeze(0))\n",
    "        input_seq = torch.cat([input_seq[1:], output[-1].unsqueeze(0)])\n",
    "\n",
    "    # Concatenate and inverse transform\n",
    "    preds = torch.cat(predictions).detach().numpy()\n",
    "    preds_inv = scaler.inverse_transform(preds)\n",
    "    zone_preds = np.clip(preds_inv[:, zone_index], 0, None)\n",
    "\n",
    "    # Plot\n",
    "    hours = list(range(horizon))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(hours, zone_preds)\n",
    "    plt.title(f\"Predicted Dropoff Count for Zone {zone_id} on a Generic Day\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Predicted Dropoffs\")\n",
    "    plt.xticks(hours)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return list(zip(hours, zone_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee8f8b5-b8b3-481b-a330-a4576e18e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_generic_day_zone(\n",
    "    model=model,\n",
    "    X_seed=X_train.clone(),\n",
    "    edge_index=edge_index,\n",
    "    scaler=scaler,\n",
    "    feature_names=agg_pivoted.columns.tolist(),\n",
    "    zone_id=107,\n",
    "    horizon=24\n",
    ")\n",
    "\n",
    "predict_generic_day_zone(\n",
    "    model=model,\n",
    "    X_seed=X_train.clone(),\n",
    "    edge_index=edge_index,\n",
    "    scaler=scaler,\n",
    "    feature_names=agg_pivoted.columns.tolist(),\n",
    "    zone_id=148,\n",
    "    horizon=24\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef71408d-2768-4272-a81c-0a17e4177c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b1d30-c96d-43d9-a6ed-4ad025016d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058fffdf-0a21-43b1-ac60-208e399cd8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
